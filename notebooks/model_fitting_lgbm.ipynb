{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this notebook as the main notebook to generate predictions or submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/intermediate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import data_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/intermediate/data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2951</th>\n",
       "      <th>2952</th>\n",
       "      <th>2953</th>\n",
       "      <th>2954</th>\n",
       "      <th>2955</th>\n",
       "      <th>2956</th>\n",
       "      <th>2957</th>\n",
       "      <th>2958</th>\n",
       "      <th>2959</th>\n",
       "      <th>2960</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P239476</td>\n",
       "      <td>Non-Essential</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P234427</td>\n",
       "      <td>Non-Essential</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P234429</td>\n",
       "      <td>Non-Essential</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P234430</td>\n",
       "      <td>Non-Essential</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P239467</td>\n",
       "      <td>Essential</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>nucleus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2961 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0              1    2    3    4    5    6    7    8    9     ... 2951  \\\n",
       "0  P239476  Non-Essential   No   No   No   No   No   No   No   No  ...   No   \n",
       "1  P234427  Non-Essential   No   No   No   No   No   No   No   No  ...   No   \n",
       "2  P234429  Non-Essential   No   No   No  Yes   No   No   No   No  ...   No   \n",
       "3  P234430  Non-Essential   No   No   No   No   No   No   No   No  ...   No   \n",
       "4  P239467      Essential   No   No   No   No   No   No   No   No  ...   No   \n",
       "\n",
       "  2952 2953 2954 2955 2956 2957 2958     2959 2960  \n",
       "0   No  Yes   No   No  Yes   No   No  nucleus    0  \n",
       "1   No   No   No   No  Yes   No   No  nucleus    0  \n",
       "2   No   No   No   No   No   No   No  nucleus    0  \n",
       "3  Yes   No   No   No  Yes   No   No  nucleus    0  \n",
       "4   No   No   No   No  Yes   No   No  nucleus    0  \n",
       "\n",
       "[5 rows x 2961 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     366\n",
       "1     192\n",
       "2      69\n",
       "3      58\n",
       "4      43\n",
       "5      43\n",
       "6      35\n",
       "7      18\n",
       "8      17\n",
       "9      10\n",
       "10      4\n",
       "11      3\n",
       "12      2\n",
       "13      1\n",
       "14      1\n",
       "Name: 2960, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[2960].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appears that the majority of features boolean, many are categorical, some may be continuous? Have yet to see any that are.\n",
    "\n",
    "Also worth noting that the column names are integers, not strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "field_descriptions_fpath = data_tools.field_descriptions_fpath\n",
    "fields = data_tools.parse_field_descriptions(field_descriptions_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2960"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this to select features\n",
    "selected_features = set(fields[[0]][~fields[0].str.contains(\"aasdfasdf\")].index) - {0}\n",
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(df_, selected_features, target_col=None, resample=True, dtypes=None, seed=None):\n",
    "    '''Takes a DataFrame and returns features to pass into model.'''\n",
    "    # Handle Missing Values\n",
    "    # LightGBM should handle this\n",
    "    df_ = df_.replace(\"?\", np.nan)  # Replace ? mark with NaN\n",
    "    \n",
    "    # Convert to correct data types\n",
    "    if dtypes is not None:\n",
    "        df_ = df_.astype(dtypes)\n",
    "    \n",
    "    # Use only selected features\n",
    "    X = df_[set(selected_features) - {target_col}]\n",
    "    if target_col is not None:\n",
    "        y = df_[target_col]\n",
    "    \n",
    "    # Upsample Minority Classes\n",
    "    # Typically done on training dataset, but some classes are too small\n",
    "    if resample:\n",
    "        ros = RandomOverSampler(sampling_strategy={i : 5 for i in range(10, 15)}, random_state=seed)\n",
    "        if target_col is not None:\n",
    "            X, y = ros.fit_resample(X, y)\n",
    "        \n",
    "    # Return Datasets\n",
    "    if target_col is not None:\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Split the dataset into features and labels (also drop column with the protein ID)\n",
    "X, y = data_pipeline(df, selected_features, target_col=2960, resample=True, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     366\n",
       "1     192\n",
       "2      69\n",
       "3      58\n",
       "4      43\n",
       "5      43\n",
       "6      35\n",
       "7      18\n",
       "8      17\n",
       "9      10\n",
       "10      5\n",
       "11      5\n",
       "12      5\n",
       "13      5\n",
       "14      5\n",
       "Name: 2960, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "* Will need to convery all datatype to int, float or bool (OR categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=SEED)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.4, stratify=y_train, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((420, 2959), (280, 2959), (176, 2959))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the accuracy metric\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "def accuracy(y_true, y_pred):\n",
    "    preds = y_pred.reshape(15, -1)\n",
    "    preds = preds.argmax(axis = 0)\n",
    "    return 'acc.', accuracy_score(y_true, preds), True\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    preds = y_pred.reshape(15, -1)\n",
    "    preds = preds.argmax(axis = 0)\n",
    "    return 'bal. acc.', balanced_accuracy_score(y_true, preds), True\n",
    "\n",
    "def f1_macro(y_true, y_pred):\n",
    "    preds = y_pred.reshape(15, -1)\n",
    "    preds = preds.argmax(axis = 0)\n",
    "    return 'f1', f1_score(y_true, preds, average='macro'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'random_state' : SEED,\n",
    "    'reg_alpha': 0.5,\n",
    "#     'reg_lambda' : 0.5,\n",
    "    'max_depth' : 8,\n",
    "    'num_leaves': 127,\n",
    "#     'feature_fraction' : 0.8,\n",
    "#     'min_child_samples': 40,\n",
    "    'learning_rate' : 0.01,\n",
    "    'n_estimators': 5000,\n",
    "}\n",
    "model = lgb.LGBMClassifier(**hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[292]\ttrain's multi_logloss: 0.149161\ttrain's f1: 1\tval's multi_logloss: 0.265819\tval's f1: 0.784054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, max_depth=8, n_estimators=5000,\n",
       "               num_leaves=127, objective='multiclass', random_state=42,\n",
       "               reg_alpha=0.5)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_params={\n",
    "    \"early_stopping_rounds\": 50, \n",
    "    \"eval_metric\" : f1_macro, #'logloss',\n",
    "    \"eval_set\" : [(X_train, y_train), (X_val, y_val)],\n",
    "    'eval_names': ['train', 'val'],\n",
    "    'verbose': 500,\n",
    "    'feature_name': 'auto', # that's actually the default\n",
    "    'categorical_feature': 'auto' # that's actually the default\n",
    "}\n",
    "model.fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        73\n",
      "           1       1.00      1.00      1.00        38\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        12\n",
      "           4       1.00      1.00      1.00         9\n",
      "           5       1.00      1.00      1.00         9\n",
      "           6       0.88      1.00      0.93         7\n",
      "           7       1.00      0.50      0.67         4\n",
      "           8       1.00      0.67      0.80         3\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       1.00      1.00      1.00         1\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.98       176\n",
      "   macro avg       0.92      0.88      0.89       176\n",
      "weighted avg       0.98      0.98      0.98       176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8777777777777778"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[200]\ttrain's multi_logloss: 0.0596509\tval's multi_logloss: 0.0649741\n",
      "[400]\ttrain's multi_logloss: 0.00721598\tval's multi_logloss: 0.00768096\n",
      "[600]\ttrain's multi_logloss: 0.00171657\tval's multi_logloss: 0.00172802\n",
      "[800]\ttrain's multi_logloss: 0.000869687\tval's multi_logloss: 0.000826277\n",
      "[1000]\ttrain's multi_logloss: 0.000594973\tval's multi_logloss: 0.000547102\n",
      "[1200]\ttrain's multi_logloss: 0.000474379\tval's multi_logloss: 0.000430782\n",
      "[1400]\ttrain's multi_logloss: 0.000401035\tval's multi_logloss: 0.000361264\n",
      "[1600]\ttrain's multi_logloss: 0.000355136\tval's multi_logloss: 0.000316594\n",
      "Early stopping, best iteration is:\n",
      "[1700]\ttrain's multi_logloss: 0.000330908\tval's multi_logloss: 0.000293441\n",
      "CPU times: user 2min 35s, sys: 3.64 s, total: 2min 38s\n",
      "Wall time: 19.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, n_estimators=5000, objective='multiclass',\n",
       "               random_state=42)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_full, y_full = data_pipeline(df, selected_features, target_col=2960, resample=False)\n",
    "full_model = lgb.LGBMClassifier(**hyper_params)\n",
    "fit_params['verbose'] = 200\n",
    "full_model.fit(X_full, y_full, **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/intermediate/data_types_dict.pkl', 'rb') as handle:\n",
    "    dtypes = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv(\"../data/raw/test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 381 entries, 0 to 380\n",
      "Columns: 2960 entries, 0 to 2959\n",
      "dtypes: float64(592), int64(632), object(1736)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "testdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'category'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypes.pop(2960)  # Remove target variable from datatype specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_kaggle_ids = testdf[0]\n",
    "X_kaggle = data_pipeline(testdf, selected_features - {2960}, resample=False, dtypes=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(testdf[0]) == set(X_kaggle_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's pass the testdf through the pipeline we used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.601050\n",
       "1     0.044619\n",
       "2     0.076115\n",
       "3     0.036745\n",
       "4     0.118110\n",
       "5     0.026247\n",
       "6     0.007874\n",
       "7     0.007874\n",
       "8     0.026247\n",
       "11    0.039370\n",
       "14    0.015748\n",
       "dtype: float64"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_kaggle = pd.Series(full_model.predict(X_kaggle))\n",
    "y_kaggle.value_counts().sort_index() / len(y_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.424594\n",
       "1     0.222738\n",
       "2     0.080046\n",
       "3     0.067285\n",
       "4     0.049884\n",
       "5     0.049884\n",
       "6     0.040603\n",
       "7     0.020882\n",
       "8     0.019722\n",
       "9     0.011601\n",
       "10    0.004640\n",
       "11    0.003480\n",
       "12    0.002320\n",
       "13    0.001160\n",
       "14    0.001160\n",
       "Name: 2960, dtype: float64"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with class distribution of training set\n",
    "df[2960].value_counts().sort_index() / len(df[2960])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P234062</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P234081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P234086</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P234087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P234094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  Label\n",
       "0  P234062      2\n",
       "1  P234081      0\n",
       "2  P234086      2\n",
       "3  P234087      0\n",
       "4  P234094      0"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now create the kaggle submission file\n",
    "submission = pd.concat((X_kaggle_ids, y_kaggle), axis=1)\n",
    "submission.columns = ['Key', 'Label']\n",
    "submission = submission.sort_values('Key').reset_index(drop=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(submission['Key']) == set(testdf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'submission-2021_03_30-02.06.csv'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = datetime.today().strftime('%Y_%m_%d-%H.%M')\n",
    "submission_fname = f\"submission-{timestamp}.csv\"\n",
    "submission.to_csv(submission_fname, index=False, header=True)\n",
    "submission_fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
