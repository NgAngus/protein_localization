{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook engineers features, fills missing values, and provides a way to impute missing values of features using intraclass modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LOCAL = True\n",
    "data_fpath = '../data/raw/' if LOCAL else '/kaggle/input/protein-localization/'\n",
    "out_fpath = '../data/intermediate/' if LOCAL else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import data_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types\n",
    "There are a few main “types” of features available, listed here:\n",
    "* ESSENTIAL\n",
    "* CLASS\n",
    "* COMPLEX\n",
    "* PHENOTYPE\n",
    "* MOTIF\n",
    "* Chromosome\n",
    "* NUM INTERACTING WITH FUNCTION (int)\n",
    "* INTERACTING PROTEIN type\n",
    "* INTERACTING PROTEIN corr (float)\n",
    "* Function\n",
    "* Localization\n",
    "\n",
    "Pretty much all are categorical except the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class actin related proteins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class actins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class adaptins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0\n",
       "0                            protein\n",
       "1                          essential\n",
       "2  class actin related proteins     \n",
       "3                class actins       \n",
       "4                     class adaptins"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_descriptions_fpath = data_tools.field_descriptions_fpath\n",
    "fields = data_tools.parse_field_descriptions(field_descriptions_fpath)\n",
    "fields[[0]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatype Specification\n",
    "def feat_dtype(col_num, ints, floats):\n",
    "    if col_num in ints:\n",
    "        return 'int'\n",
    "    if col_num in floats:\n",
    "        return 'float'\n",
    "    # We assume everything else is categorical\n",
    "    return 'category'\n",
    "\n",
    "float_indices = fields[0].str.contains(\"interacting protein\") & fields[0].str.contains(\"corr\")\n",
    "int_indices = fields[0].str.contains(\"num interacting\")\n",
    "\n",
    "### 444 := chromosome #, coerce to float, so we fill missing, then turn into category later\n",
    "float_feats = set(fields[[0]][float_indices].index) - {0, 2960} | {444}\n",
    "int_feats = set(fields[[0]][int_indices].index) - {0, 2960}\n",
    "\n",
    "dtypes = {col_num : feat_dtype(col_num, int_feats, float_feats) for col_num in range(1,2961)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the data type dictionary so we can load it later when loading the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data type dictionary to pickle\n",
    "with open(f'{out_fpath}data_types_dict.pkl', 'wb') as handle:\n",
    "    pickle.dump(dtypes, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{out_fpath}data_types_dict.pkl', 'rb') as handle:\n",
    "    dtypes = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angus/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (444) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{data_fpath}train.csv\", header=None)\n",
    "df = df.replace(\"?\", np.nan)  # Replace ? mark with NaN\n",
    "df = df.astype(dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angus/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (524,720,768,1112,1182,1288,1302,1352,1354,1378,1434,1436,1488,1502,1504,1604,1608,1734,1838,1908,1914,1942,1996,2246,2270,2328,2460,2514,2576,2620,2724,2758,2930) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "testdf = pd.read_csv(f\"{data_fpath}test.csv\", header=None)\n",
    "testdf = testdf.replace(\"?\", np.nan)  # Replace ? mark with NaN\n",
    "dtypes.pop(2960, None)  # Pop target from data types\n",
    "testdf = testdf.astype(dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        44\n",
       "444       1\n",
       "534       4\n",
       "566       1\n",
       "674       1\n",
       "       ... \n",
       "2940    862\n",
       "2941    862\n",
       "2942    862\n",
       "2943    862\n",
       "2944    862\n",
       "Length: 815, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing Values\n",
    "df[df.isna().any()[lambda x: x].index].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        17\n",
       "444      59\n",
       "463       1\n",
       "475       1\n",
       "483       1\n",
       "       ... \n",
       "2955    381\n",
       "2956    381\n",
       "2957    381\n",
       "2958    381\n",
       "2959    381\n",
       "Length: 158, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing Values\n",
    "testdf[testdf.isna().any()[lambda x: x].index].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that for column 1 and 444 which are fairly important features, the number of missing values in training data is fairly small. It is worth imputing them with the most common value in their class so we can use SMOTE later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_by_class_mode(df, col, target_col=2960):\n",
    "    '''Imputes a column with missing values by using\n",
    "    the mode of that feature within the class.\n",
    "    df : full dataframe with target_col\n",
    "    col : column to impute\n",
    "    '''\n",
    "    # Create a map of class to mode of feature in col\n",
    "    mode_map = df.loc[:, [col, target_col]].groupby(target_col)[col].agg(pd.Series.mode).to_dict()\n",
    "    # Make all values lists in case ties\n",
    "    mode_map = {k : np.asarray(v).tolist() for k, v in mode_map.items()}\n",
    "    mode_map = {k : [v] if not isinstance(v, list) else v for k, v in mode_map.items()}\n",
    "    # Make copy of column to impute\n",
    "    col_to_impute = df[col].copy()\n",
    "    # Identify rows with missing values\n",
    "    missing_idxs = col_to_impute.isna()[lambda x: x].index\n",
    "    col_to_impute.iloc[missing_idxs] = df.iloc[missing_idxs, target_col].apply(lambda x: choice(mode_map[x]))\n",
    "    return col_to_impute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[1] = impute_by_class_mode(df, 1)\n",
    "df[444] = impute_by_class_mode(df, 444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534       4\n",
       "566       1\n",
       "674       1\n",
       "720       9\n",
       "732       1\n",
       "       ... \n",
       "2940    862\n",
       "2941    862\n",
       "2942    862\n",
       "2943    862\n",
       "2944    862\n",
       "Length: 813, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing Values\n",
    "df[df.isna().any()[lambda x: x].index].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protein Interactions File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_colnames = ['protein1', 'protein2', 'type', 'strength']\n",
    "df2 = pd.read_csv(f\"{data_fpath}protein_interactions.csv\", header=None, names=interaction_colnames,\n",
    "    dtype={\n",
    "        'type' : 'category',\n",
    "    }\n",
    ")\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The strength values have a random period at\n",
    "# the end of the values preventing it from being parsed as numeric\n",
    "df2['strength'] = df2['strength'].str.rstrip('.').replace(\"?\", np.nan)\n",
    "df2['strength'] = pd.to_numeric(df2['strength'].str.rstrip('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein1</th>\n",
       "      <th>protein2</th>\n",
       "      <th>type</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P238510</td>\n",
       "      <td>P239467</td>\n",
       "      <td>Genetic</td>\n",
       "      <td>0.252653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P235550</td>\n",
       "      <td>P239467</td>\n",
       "      <td>Physical</td>\n",
       "      <td>0.709248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P235621</td>\n",
       "      <td>P239467</td>\n",
       "      <td>Physical</td>\n",
       "      <td>-0.001239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P235265</td>\n",
       "      <td>P239467</td>\n",
       "      <td>Physical</td>\n",
       "      <td>0.482255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P234935</td>\n",
       "      <td>P234445</td>\n",
       "      <td>Physical</td>\n",
       "      <td>-0.460856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein1 protein2      type  strength\n",
       "0  P238510  P239467   Genetic  0.252653\n",
       "1  P235550  P239467  Physical  0.709248\n",
       "2  P235621  P239467  Physical -0.001239\n",
       "3  P235265  P239467  Physical  0.482255\n",
       "4  P234935  P234445  Physical -0.460856"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protein Interactions Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2486, 1243, 1243]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ppi := protein-protein interactions\n",
    "qry = fields[0].str.contains(\"interacting protein\")\n",
    "ppi_features = set(fields[[0]][qry].index) - {0}\n",
    "qry_corr = fields[0].str.contains(\"corr\")\n",
    "qry_type = fields[0].str.contains(\"type\")\n",
    "\n",
    "ppi_corr_features = set(fields[[0]][qry & qry_corr].index) - {0}\n",
    "ppi_type_features = set(fields[[0]][qry & qry_type].index) - {0}\n",
    "[len(x) for x in (ppi_features, ppi_corr_features, ppi_type_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_feat(protein : str):\n",
    "    '''E.g.: interacting protein p235094 corr'''\n",
    "    return f\"interacting protein {protein.lower()} corr\"\n",
    "\n",
    "def type_feat(protein : str):\n",
    "    '''E.g.: interacting protein p235094 corr'''\n",
    "    return f\"interacting protein {protein.lower()} type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'interacting protein p239476 corr'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tools.feature_name(fields, 460)  # Example interaction feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map from feature name to column\n",
    "feat_to_col = data_tools.feat_to_col_map(data_tools.field_descriptions_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "830"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_to_col[corr_feat('P238510')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'interacting protein p235082 corr'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tools.feature_name(fields, 2940)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need a way to fill the protein interaction cells with the type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This protein is not present in the dataset at all! So how can we use the PPI features? Possible features to engineer:\n",
    "* Sum/min/max/mean/#negof interactions corr\n",
    "* mode of interactions\n",
    "* percent of interactions that are genetic\n",
    "* meta feature: mode of the CLASS of proteins that interact (data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive Features from PPI Correlation\n",
    "df['interaction_sum'] = df.loc[:, ppi_corr_features].sum(axis=1)\n",
    "df['interaction_mean'] = df.loc[:, ppi_corr_features].mean(axis=1)\n",
    "df['interaction_max'] = df.loc[:, ppi_corr_features].max(axis=1)\n",
    "df['interaction_max2'] = df.loc[:, ppi_corr_features].apply(lambda row: row.nlargest(2).values[-1], axis=1)\n",
    "df['interaction_max3'] = df.loc[:, ppi_corr_features].apply(lambda row: row.nlargest(3).values[-1], axis=1)\n",
    "df['interaction_min'] = df.loc[:, ppi_corr_features].min(axis=1)\n",
    "df['interaction_neg'] = df.loc[:, ppi_corr_features].lt(0).sum(axis=1)\n",
    "df['interaction_count'] = (df.loc[:, ppi_corr_features] != 0).sum(axis=1)\n",
    "df['interaction_count'] = df['interaction_count'] - min(df['interaction_count'])\n",
    "df['interaction_pos'] = df.loc[:, ppi_corr_features].gt(0).sum(axis=1)\n",
    "df['interaction_std'] = df.loc[:, ppi_corr_features].std(axis=1)\n",
    "df['interaction_skew'] = df.loc[:, ppi_corr_features].apply(\n",
    "    lambda row: sp.stats.skew(row, nan_policy='omit'), axis=1).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive Features from PPI Type\n",
    "df['ppi_genetic_count'] = df.loc[:, ppi_type_features].apply(\n",
    "    lambda row: row.astype(str).str.count(\"Genetic\").sum(), axis=1)\n",
    "df['ppi_physical_count'] = df.loc[:, ppi_type_features].apply(\n",
    "    lambda row: row.astype(str).str.count(\"Physical\").sum(), axis=1)\n",
    "df['ppi_gen_phys_count'] = df.loc[:, ppi_type_features].apply(\n",
    "    lambda row: row.astype(str).str.count(\"Genetic-Physical\").sum(), axis=1)\n",
    "df['ppi_genetic_physical_ratio'] = df['ppi_genetic_count'] / (1 + df['ppi_physical_count'])\n",
    "ppi_type_feats = ['ppi_genetic_count', 'ppi_physical_count', 'ppi_gen_phys_count']\n",
    "df['ppi_dom_type'] = df[ppi_type_feats].idxmax(axis='columns').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proteins of highest correlation, since that is the point of this dataset\n",
    "# Note that if all ties, we return the first index\n",
    "df['max_corr_ppi'] = df[ppi_corr_features].idxmax(axis='columns').astype('category')\n",
    "df['min_corr_ppi'] = df[ppi_corr_features].idxmax(axis='columns').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I suspect this will be the ultimate feature.\n",
    "import functools\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def ppi_to_localization(protein, target=2959):\n",
    "    '''This function takes a PPI feature and determines the\n",
    "    localization of the protein if it exists in training data.'''\n",
    "    full_feat_name = data_tools.feature_name(fields, protein)\n",
    "    ppi_name = full_feat_name.split()[-2].upper()  # Protein name\n",
    "    localizations = list(df.loc[df[0] == ppi_name, target].values)\n",
    "    if not localizations:\n",
    "        return 'unknown'\n",
    "    mode = list(pd.Series(localizations).mode().values)\n",
    "    return choice(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['strongest_localization'] = df['max_corr_ppi'].apply(ppi_to_localization).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       460\n",
       "1       460\n",
       "2       460\n",
       "3       658\n",
       "4       736\n",
       "       ... \n",
       "857    1734\n",
       "858     460\n",
       "859     460\n",
       "860     460\n",
       "861     460\n",
       "Name: max_corr_ppi, Length: 862, dtype: category\n",
       "Categories (381, int64): [460, 466, 468, 474, ..., 2156, 2164, 2168, 2174]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all proteins that are nonzero\n",
    "df['max_corr_ppi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_mode(A):\n",
    "    if not A:\n",
    "        return 'unknown'\n",
    "    return choice(pd.Series(A).mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = df.loc[:,ppi_corr_features].columns\n",
    "bt = df.loc[:,ppi_corr_features].apply(lambda x: x > 0)\n",
    "df['mode_localization_pos'] = bt.apply(\n",
    "    lambda x: localization_mode([ppi_to_localization(prot, 2960) for prot in cols[x.values]]),\n",
    "    axis=1).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            unknown\n",
       "1            unknown\n",
       "2            unknown\n",
       "3      Non-Essential\n",
       "4          Essential\n",
       "           ...      \n",
       "857    Non-Essential\n",
       "858          unknown\n",
       "859          unknown\n",
       "860          unknown\n",
       "861          unknown\n",
       "Length: 862, dtype: category\n",
       "Categories (3, object): ['Essential', 'Non-Essential', 'unknown']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf = df.loc[:,ppi_corr_features].apply(lambda x: x > 0)\n",
    "asdf.apply(\n",
    "    lambda x: localization_mode([ppi_to_localization(prot, 1) for prot in cols[x.values]]),\n",
    "    axis=1).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955,\n",
       "            2956, 2957, 2958],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_feats_qry = fields[0].str.contains(\"function\")\n",
    "function_feats = fields[[0]][function_feats_qry].index\n",
    "function_feats = function_feats[function_feats > 2900]  # Interested in the ones that are missing from test_data\n",
    "function_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf[function_feats].replace('?', np.nan).sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features are all missing in test data! Best to drop them from training data unless we can fill it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(df, fields, dtypes, impute=False, target_col=None, seed=None):\n",
    "    '''Takes a DataFrame and returns features to pass into model.'''\n",
    "    # Handle Missing Values\n",
    "    # TODO: Try using zeros\n",
    "    # LightGBM should handle NasNs though\n",
    "    df = df.replace(\"?\", np.nan)  # Replace ? mark with NaN\n",
    "    \n",
    "    # Convert to correct data types\n",
    "    if target_col is None:\n",
    "        dtypes.pop(2960)  # labels aren't in test data\n",
    "    df = df.astype(dtypes)\n",
    "    \n",
    "    # Impute Missing Values\n",
    "    # I've selected these columns very carefully\n",
    "    impute_cols = [1, 444]\n",
    "    for col in impute_cols:\n",
    "        if impute:\n",
    "            # Impute the column\n",
    "            df[col] = impute_by_class_mode(df, col)\n",
    "        # Convert back to categorical\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    # Identify columns corresponding to PPI features\n",
    "    # PPI := protein-protein interactions\n",
    "    qry = fields[0].str.contains(\"interacting protein\")\n",
    "    ppi_features = set(fields[[0]][qry].index) - {0}\n",
    "    qry_corr = fields[0].str.contains(\"corr\")\n",
    "    qry_type = fields[0].str.contains(\"type\")\n",
    "\n",
    "    ppi_corr_features = set(fields[[0]][qry & qry_corr].index) - {0}\n",
    "    ppi_type_features = set(fields[[0]][qry & qry_type].index) - {0}\n",
    "    \n",
    "    # Derive Features from PPI Correlation\n",
    "    df['interaction_sum'] = df.loc[:, ppi_corr_features].sum(axis=1)\n",
    "    df['interaction_mean'] = df.loc[:, ppi_corr_features].mean(axis=1)\n",
    "    df['interaction_max'] = df.loc[:, ppi_corr_features].max(axis=1)\n",
    "    df['interaction_max2'] = df.loc[:, ppi_corr_features].apply(lambda row: row.nlargest(2).values[-1], axis=1)\n",
    "    df['interaction_max3'] = df.loc[:, ppi_corr_features].apply(lambda row: row.nlargest(3).values[-1], axis=1)\n",
    "    df['interaction_min'] = df.loc[:, ppi_corr_features].min(axis=1)\n",
    "    df['interaction_neg'] = df.loc[:, ppi_corr_features].lt(0).sum(axis=1)\n",
    "    df['interaction_count'] = (df.loc[:, ppi_corr_features] != 0).sum(axis=1)\n",
    "    df['interaction_count'] = df['interaction_count'] - min(df['interaction_count'])\n",
    "    df['interaction_pos'] = df.loc[:, ppi_corr_features].gt(0).sum(axis=1)\n",
    "    df['interaction_std'] = df.loc[:, ppi_corr_features].std(axis=1)\n",
    "    df['interaction_skew'] = df.loc[:, ppi_corr_features].apply(\n",
    "        lambda row: sp.stats.skew(row, nan_policy='omit'), axis=1).astype(float)\n",
    "\n",
    "    # Derive Features from PPI Type\n",
    "    df['ppi_genetic_count'] = df.loc[:, ppi_type_features].apply(\n",
    "        lambda row: row.astype(str).str.count(\"Genetic\").sum(), axis=1)\n",
    "    df['ppi_physical_count'] = df.loc[:, ppi_type_features].apply(\n",
    "        lambda row: row.astype(str).str.count(\"Physical\").sum(), axis=1)\n",
    "    df['ppi_gen_phys_count'] = df.loc[:, ppi_type_features].apply(\n",
    "        lambda row: row.astype(str).str.count(\"Genetic-Physical\").sum(), axis=1)\n",
    "    df['ppi_genetic_physical_ratio'] = df['ppi_genetic_count'] / (1 + df['ppi_physical_count'])\n",
    "    ppi_type_feats = ['ppi_genetic_count', 'ppi_physical_count', 'ppi_gen_phys_count']\n",
    "    df['ppi_dom_type'] = df[ppi_type_feats].idxmax(axis='columns').astype('category')\n",
    "    \n",
    "    # Get proteins of highest correlation, since that is the point of this dataset\n",
    "    # Note that if all ties, we return the first index\n",
    "    df['max_corr_ppi'] = df[ppi_corr_features].idxmax(axis='columns').astype('category')\n",
    "    df['min_corr_ppi'] = df[ppi_corr_features].idxmax(axis='columns').astype('category')\n",
    "    df['strongest_localization'] = df['max_corr_ppi'].apply(ppi_to_localization).astype('category')\n",
    "    cols = df.loc[:,ppi_corr_features].columns\n",
    "    bt = df.loc[:,ppi_corr_features].apply(lambda x: x > 0)\n",
    "    df['mode_localization'] = bt.apply(\n",
    "        lambda x: localization_mode([ppi_to_localization(prot, 2960) for prot in cols[x.values]]),\n",
    "        axis=1).astype('category')\n",
    "    \n",
    "    # Drop Function Features\n",
    "    function_feats_qry = fields[0].str.contains(\"function\")\n",
    "    function_feats = fields[[0]][function_feats_qry].index\n",
    "    function_feats = set(function_feats[function_feats > 2900])\n",
    "    \n",
    "    # Use only selected features\n",
    "    X = df[set(df.columns) - {target_col, 0, 2959} - ppi_features - function_feats]\n",
    "    if target_col is not None:\n",
    "        y = df[target_col]\n",
    "    \n",
    "    # Return Datasets\n",
    "    if target_col is not None:\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Pipeline to Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-11f5eb5d48cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# Stop running notebook here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False  # Stop running notebook here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{data_fpath}train.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{out_fpath}data_types_dict.pkl', 'rb') as handle:\n",
    "    dtypes = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_pipeline(df, fields, dtypes, impute=True, target_col=2960, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Pipeline to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angus/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (524,720,768,1112,1182,1288,1302,1352,1354,1378,1434,1436,1488,1502,1504,1604,1608,1734,1838,1908,1914,1942,1996,2246,2270,2328,2460,2514,2576,2620,2724,2758,2930) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "testdf = pd.read_csv(f\"{data_fpath}test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{out_fpath}data_types_dict.pkl', 'rb') as handle:\n",
    "    dtypes = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angus/anaconda3/lib/python3.8/site-packages/pandas/core/algorithms.py:944: UserWarning: Unable to sort modes: '>' not supported between instances of 'numpy.ndarray' and 'str'\n",
      "  warn(f\"Unable to sort modes: {err}\")\n",
      "/Users/angus/anaconda3/lib/python3.8/site-packages/pandas/core/algorithms.py:944: UserWarning: Unable to sort modes: '<' not supported between instances of 'numpy.ndarray' and 'str'\n",
      "  warn(f\"Unable to sort modes: {err}\")\n"
     ]
    }
   ],
   "source": [
    "X_kaggle = data_pipeline(testdf, fields, dtypes, target_col=None, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 381 entries, 0 to 380\n",
      "Columns: 478 entries, 1 to ppi_gen_phys_count\n",
      "dtypes: category(449), float64(9), int64(20)\n",
      "memory usage: 327.4 KB\n"
     ]
    }
   ],
   "source": [
    "X_kaggle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_pickle(f\"{out_fpath}X.pkl\")\n",
    "y.to_pickle(f\"{out_fpath}y.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle.to_pickle(f\"{out_fpath}X_kaggle.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For One-Hot Encoding\n",
    "* need to concatenate the kaggle dataframe first, since not all categories are present in both training and kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First concat X and competition data\n",
    "combined = pd.concat((X, X_kaggle), axis=0)\n",
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some datatypes have been altered. Let's coerce them back to the correct ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_dict = X.dtypes.astype(str).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined = combined.astype(dtypes_dict)\n",
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode\n",
    "categoricals = combined.select_dtypes(include=['category']).columns\n",
    "combined_enc = pd.get_dummies(data=combined, columns=categoricals, drop_first=False)\n",
    "combined_enc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Let's split it back up into X_enc, X_kaggle_enc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_enc = combined_enc.iloc[:X.shape[0]]\n",
    "X_enc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_kaggle_enc = combined_enc.iloc[X.shape[0]:]\n",
    "X_kaggle_enc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving output (one-hot encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_enc.to_pickle(f\"{out_fpath}X_enc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle_enc.to_pickle(f\"{out_fpath}X_kaggle_enc.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
